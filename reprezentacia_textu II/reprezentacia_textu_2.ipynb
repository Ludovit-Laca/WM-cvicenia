{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reprezentacia_textu_2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1lMSFPOZwyfCx4rS6h7Ic44bEfsTJN59A","authorship_tag":"ABX9TyO54vjPxUbFds4xrIyI5Mce"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wMjVvo8IoYdc"},"source":["0.) Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OS1oB402oLjn","executionInfo":{"status":"ok","timestamp":1622564032230,"user_tz":-120,"elapsed":1107,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}},"outputId":"098337ab-ef72-4c48-9ca8-167021393dac"},"source":["import numpy as np\n","import pandas as pd\n","\n","import math\n","from sklearn.feature_extraction.text import CountVectorizer \n","\n","import nltk\n","from nltk.corpus import stopwords \n","from nltk.tokenize import word_tokenize, sent_tokenize \n","from nltk.stem import WordNetLemmatizer\n","from nltk.probability import FreqDist\n","\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","stop_words = set(stopwords.words('english')) "],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cECyQcSXltli"},"source":["1.) Load texts"]},{"cell_type":"code","metadata":{"id":"qJxw4958lsbw","executionInfo":{"status":"ok","timestamp":1622564032231,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}}},"source":["# change to your own file location\n","text1 = open(\"/content/drive/MyDrive/Škola/WM/reprezentacia_textu II/text1.txt\", \"r\").read()\n","text2 = open(\"/content/drive/MyDrive/Škola/WM/reprezentacia_textu II/text2.txt\", \"r\").read()\n","text3 = open(\"/content/drive/MyDrive/Škola/WM/reprezentacia_textu II/text3.txt\", \"r\").read()\n","text4 = open(\"/content/drive/MyDrive/Škola/WM/reprezentacia_textu II/text4.txt\", \"r\").read()\n","text5 = open(\"/content/drive/MyDrive/Škola/WM/reprezentacia_textu II/text5.txt\", \"r\").read()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHDRtiomqhE5"},"source":["2.) Breaks texts into arrays of words"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"46L3QpDaqi4q","executionInfo":{"status":"ok","timestamp":1622564032232,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}},"outputId":"7a872c34-f6bf-4ed3-be6b-be5b39c77517"},"source":["tokenized_word1=word_tokenize(text1)\n","tokenized_word2=word_tokenize(text2)\n","tokenized_word3=word_tokenize(text3)\n","tokenized_word4=word_tokenize(text4)\n","tokenized_word5=word_tokenize(text5)\n","\n","print(tokenized_word1)\n","print(tokenized_word2)\n","print(tokenized_word3)\n","print(tokenized_word4)\n","print(tokenized_word5)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['How', 'to', 'train', 'a', 'robot', '(', 'using', 'AI', 'and', 'supercomputers', ')', 'Before', 'he', 'joined', 'the', 'University', 'of', 'Texas', 'at', 'Arlington', 'as', 'an', 'Assistant', 'Professor', 'in', 'the', 'Department', 'of', 'Computer', 'Science', 'and', 'Engineering', 'and', 'founded', 'the', 'Robotic', 'Vision', 'Laboratory', 'there', ',', 'William', 'Beksi', 'interned', 'at', 'iRobot', ',', 'the', 'world', \"'s\", 'largest', 'producer', 'of', 'consumer', 'robots', '(', 'mainly', 'through', 'its', 'Roomba', 'robotic', 'vacuum', ')', '.', 'To', 'navigate', 'built', 'environments', ',', 'robots', 'must', 'be', 'able', 'to', 'sense', 'and', 'make', 'decisions', 'about', 'how', 'to', 'interact', 'with', 'their', 'locale', '.', 'Researchers', 'at', 'the', 'company', 'were', 'interested', 'in', 'using', 'machine', 'and', 'deep', 'learning', 'to', 'train', 'their', 'robots', 'to', 'learn', 'about', 'objects', ',', 'but', 'doing', 'so', 'requires', 'a', 'large', 'dataset', 'of', 'images', '.', 'While', 'there', 'are', 'millions', 'of', 'photos', 'and', 'videos', 'of', 'rooms', ',', 'none', 'were', 'shot', 'from', 'the', 'vantage', 'point', 'of', 'a', 'robotic', 'vacuum', '.', 'Efforts', 'to', 'train', 'using', 'images', 'with', 'human-centric', 'perspectives', 'failed', '.', 'Beksi', \"'s\", 'research', 'focuses', 'on', 'robotics', ',', 'computer', 'vision', ',', 'and', 'cyber-physical', 'systems', '.', '``', 'In', 'particular', ',', 'I', \"'m\", 'interested', 'in', 'developing', 'algorithms', 'that', 'enable', 'machines', 'to', 'learn', 'from', 'their', 'interactions', 'with', 'the', 'physical', 'world', 'and', 'autonomously', 'acquire', 'skills', 'necessary', 'to', 'execute', 'high-level', 'tasks', ',', \"''\", 'he', 'said', '.', 'Years', 'later', ',', 'now', 'with', 'a', 'research', 'group', 'including', 'six', 'PhD', 'computer', 'science', 'students', ',', 'Beksi', 'recalled', 'the', 'Roomba', 'training', 'problem', 'and', 'begin', 'exploring', 'solutions', '.', 'A', 'manual', 'approach', ',', 'used', 'by', 'some', ',', 'involves', 'using', 'an', 'expensive', '360', 'degree', 'camera', 'to', 'capture', 'environments', '(', 'including', 'rented', 'Airbnb', 'houses', ')', 'and', 'custom', 'software', 'to', 'stitch', 'the', 'images', 'back', 'into', 'a', 'whole', '.', 'But', 'Beksi', 'believed', 'the', 'manual', 'capture', 'method', 'would', 'be', 'too', 'slow', 'to', 'succeed', '.', 'Instead', ',', 'he', 'looked', 'to', 'a', 'form', 'of', 'deep', 'learning', 'known', 'as', 'generative', 'adversarial', 'networks', ',', 'or', 'GANs', ',', 'where', 'two', 'neural', 'networks', 'contest', 'with', 'each', 'other', 'in', 'a', 'game', 'until', 'the', \"'generator\", \"'\", 'of', 'new', 'data', 'can', 'fool', 'a', \"'discriminator\", '.', \"'\", 'Once', 'trained', ',', 'such', 'a', 'network', 'would', 'enable', 'the', 'creation', 'of', 'an', 'infinite', 'number', 'of', 'possible', 'rooms', 'or', 'outdoor', 'environments', ',', 'with', 'different', 'kinds', 'of', 'chairs', 'or', 'tables', 'or', 'vehicles', 'with', 'slightly', 'different', 'forms', ',', 'but', 'still', '--', 'to', 'a', 'person', 'and', 'a', 'robot', '--', 'identifiable', 'objects', 'with', 'recognizable', 'dimensions', 'and', 'characteristics', '.', '``', 'You', 'can', 'perturb', 'these', 'objects', ',', 'move', 'them', 'into', 'new', 'positions', ',', 'use', 'different', 'lights', ',', 'color', 'and', 'texture', ',', 'and', 'then', 'render', 'them', 'into', 'a', 'training', 'image', 'that', 'could', 'be', 'used', 'in', 'dataset', ',', \"''\", 'he', 'explained', '.', '``', 'This', 'approach', 'would', 'potentially', 'provide', 'limitless', 'data', 'to', 'train', 'a', 'robot', 'on', '.', \"''\", '``', 'Manually', 'designing', 'these', 'objects', 'would', 'take', 'a', 'huge', 'amount', 'of', 'resources', 'and', 'hours', 'of', 'human', 'labor', 'while', ',', 'if', 'trained', 'properly', ',', 'the', 'generative', 'networks', 'can', 'make', 'them', 'in', 'seconds', ',', \"''\", 'said', 'Mohammad', 'Samiul', 'Arshad', ',', 'a', 'graduate', 'student', 'in', 'Beksi', \"'s\", 'group', 'involved', 'in', 'the', 'research', '.', 'GENERATING', 'OBJECTS', 'FOR', 'SYNTHETIC', 'SCENES', 'After', 'some', 'initial', 'attempts', ',', 'Beksi', 'realized', 'his', 'dream', 'of', 'creating', 'photorealistic', 'full', 'scenes', 'was', 'presently', 'out', 'of', 'reach', '.', '``', 'We', 'took', 'a', 'step', 'back', 'and', 'looked', 'at', 'current', 'research', 'to', 'determine', 'how', 'to', 'start', 'at', 'a', 'smaller', 'scale', '--', 'generating', 'simple', 'objects', 'in', 'environments', '.', \"''\", 'Beksi', 'and', 'Arshad', 'presented', 'PCGAN', ',', 'the', 'first', 'conditional', 'generative', 'adversarial', 'network', 'to', 'generate', 'dense', 'colored', 'point', 'clouds', 'in', 'an', 'unsupervised', 'mode', ',', 'at', 'the', 'International', 'Conference', 'on', '3D', 'Vision', '(', '3DV', ')', 'in', 'Nov.', '2020', '.', 'Their', 'paper', ',', '``', 'A', 'Progressive', 'Conditional', 'Generative', 'Adversarial', 'Network', 'for', 'Generating', 'Dense', 'and', 'Colored', '3D', 'Point', 'Clouds', ',', \"''\", 'shows', 'their', 'network', 'is', 'capable', 'of', 'learning', 'from', 'a', 'training', 'set', '(', 'derived', 'from', 'ShapeNetCore', ',', 'a', 'CAD', 'model', 'database', ')', 'and', 'mimicking', 'a', '3D', 'data', 'distribution', 'to', 'produce', 'colored', 'point', 'clouds', 'with', 'fine', 'details', 'at', 'multiple', 'resolutions', '.', '``', 'There', 'was', 'some', 'work', 'that', 'could', 'generate', 'synthetic', 'objects', 'from', 'these', 'CAD', 'model', 'datasets', ',', \"''\", 'he', 'said', '.', '``', 'But', 'no', 'one', 'could', 'yet', 'handle', 'color', '.', \"''\", 'In', 'order', 'to', 'test', 'their', 'method', 'on', 'a', 'diversity', 'of', 'shapes', ',', 'Beksi', \"'s\", 'team', 'chose', 'chairs', ',', 'tables', ',', 'sofas', ',', 'airplanes', ',', 'and', 'motorcycles', 'for', 'their', 'experiment', '.', 'The', 'tool', 'allows', 'the', 'researchers', 'to', 'access', 'the', 'near-infinite', 'number', 'of', 'possible', 'versions', 'of', 'the', 'set', 'of', 'objects', 'the', 'deep', 'learning', 'system', 'generates', '.', '``', 'Our', 'model', 'first', 'learns', 'the', 'basic', 'structure', 'of', 'an', 'object', 'at', 'low', 'resolutions', 'and', 'gradually', 'builds', 'up', 'towards', 'high-level', 'details', ',', \"''\", 'he', 'explained', '.', '``', 'The', 'relationship', 'between', 'the', 'object', 'parts', 'and', 'their', 'colors', '--', 'for', 'examples', ',', 'the', 'legs', 'of', 'the', 'chair/table', 'are', 'the', 'same', 'color', 'while', 'seat/top', 'are', 'contrasting', '--', 'is', 'also', 'learned', 'by', 'the', 'network', '.', 'We', \"'re\", 'starting', 'small', ',', 'working', 'with', 'objects', ',', 'and', 'building', 'to', 'a', 'hierarchy', 'to', 'do', 'full', 'synthetic', 'scene', 'generation', 'that', 'would', 'be', 'extremely', 'useful', 'for', 'robotics', '.', \"''\", 'They', 'generated', '5,000', 'random', 'samples', 'for', 'each', 'class', 'and', 'performed', 'an', 'evaluation', 'using', 'a', 'number', 'of', 'different', 'methods', '.', 'They', 'evaluated', 'both', 'point', 'cloud', 'geometry', 'and', 'color', 'using', 'a', 'variety', 'of', 'common', 'metrics', 'in', 'the', 'field', '.', 'Their', 'results', 'showed', 'that', 'PCGAN', 'is', 'capable', 'of', 'synthesizing', 'high-quality', 'point', 'clouds', 'for', 'a', 'disparate', 'array', 'of', 'object', 'classes', '.', 'SIM2REAL', 'Another', 'issue', 'that', 'Beksi', 'is', 'working', 'on', 'is', 'known', 'colloquially', 'as', \"'sim2real\", '.', \"'\", '``', 'You', 'have', 'real', 'training', 'data', ',', 'and', 'synthetic', 'training', 'data', ',', 'and', 'there', 'can', 'be', 'subtle', 'differences', 'in', 'how', 'an', 'AI', 'system', 'or', 'robot', 'learns', 'from', 'them', ',', \"''\", 'he', 'said', '.', '``', \"'Sim2real\", \"'\", 'looks', 'at', 'how', 'to', 'quantify', 'those', 'differences', 'and', 'make', 'simulations', 'more', 'realistic', 'by', 'capturing', 'the', 'physics', 'of', 'that', 'scene', '--', 'friction', ',', 'collisions', ',', 'gravity', '--', 'and', 'by', 'using', 'ray', 'or', 'photon', 'tracing', '.', \"''\", 'The', 'next', 'step', 'for', 'Beksi', \"'s\", 'team', 'is', 'to', 'deploy', 'the', 'software', 'on', 'a', 'robot', ',', 'and', 'see', 'how', 'it', 'works', 'in', 'relationship', 'to', 'the', 'sim-to-real', 'domain', 'gap', '.', 'The', 'training', 'of', 'the', 'PCGAN', 'model', 'was', 'made', 'possible', 'by', 'TACC', \"'s\", 'Maverick', '2', 'deep', 'learning', 'resource', ',', 'which', 'Beksi', 'and', 'his', 'students', 'were', 'able', 'to', 'access', 'through', 'the', 'University', 'of', 'Texas', 'Cyberinfrastructure', 'Research', '(', 'UTRC', ')', 'program', ',', 'which', 'provides', 'computing', 'resources', 'to', 'researchers', 'at', 'any', 'of', 'the', 'UT', 'System', \"'s\", '14', 'institutions', '.', '``', 'If', 'you', 'want', 'to', 'increase', 'resolution', 'to', 'include', 'more', 'points', 'and', 'more', 'detail', ',', 'that', 'increase', 'comes', 'with', 'an', 'increase', 'in', 'computational', 'cost', ',', \"''\", 'he', 'noted', '.', '``', 'We', 'do', \"n't\", 'have', 'those', 'hardware', 'resources', 'in', 'my', 'lab', ',', 'so', 'it', 'was', 'essential', 'to', 'make', 'use', 'of', 'TACC', 'to', 'do', 'that', '.', \"''\", 'In', 'addition', 'to', 'computation', 'needs', ',', 'Beksi', 'required', 'extensive', 'storage', 'for', 'the', 'research', '.', '``', 'These', 'datasets', 'are', 'huge', ',', 'especially', 'the', '3D', 'point', 'clouds', ',', \"''\", 'he', 'said', '.', '``', 'We', 'generate', 'hundreds', 'of', 'megabytes', 'of', 'data', 'per', 'second', ';', 'each', 'point', 'cloud', 'is', 'around', '1', 'million', 'points', '.', 'You', 'need', 'an', 'enormous', 'amount', 'of', 'storage', 'for', 'that', '.', \"''\", 'While', 'Beksi', 'says', 'the', 'field', 'is', 'still', 'a', 'long', 'way', 'from', 'having', 'really', 'good', 'robust', 'robots', 'that', 'can', 'be', 'autonomous', 'for', 'long', 'periods', 'of', 'time', ',', 'doing', 'so', 'would', 'benefit', 'multiple', 'domains', ',', 'including', 'health', 'care', ',', 'manufacturing', ',', 'and', 'agriculture', '.', '``', 'The', 'publication', 'is', 'just', 'one', 'small', 'step', 'toward', 'the', 'ultimate', 'goal', 'of', 'generating', 'synthetic', 'scenes', 'of', 'indoor', 'environments', 'for', 'advancing', 'robotic', 'perception', 'capabilities', ',', \"''\", 'he', 'said', '.']\n","['Artificial', 'intelligence', 'puts', 'focus', 'on', 'the', 'life', 'of', 'insects', 'Scientists', 'are', 'combining', 'artificial', 'intelligence', 'and', 'advanced', 'computer', 'technology', 'with', 'biological', 'know', 'how', 'to', 'identify', 'insects', 'with', 'supernatural', 'speed', '.', 'This', 'opens', 'up', 'new', 'possibilities', 'for', 'describing', 'unknown', 'species', 'and', 'for', 'tracking', 'the', 'life', 'of', 'insects', 'across', 'space', 'and', 'time', 'Insects', 'are', 'the', 'most', 'diverse', 'group', 'of', 'animals', 'on', 'Earth', 'and', 'only', 'a', 'small', 'fraction', 'of', 'these', 'have', 'been', 'found', 'and', 'formally', 'described', '.', 'In', 'fact', ',', 'there', 'are', 'so', 'many', 'species', 'that', 'discovering', 'all', 'of', 'them', 'in', 'the', 'near', 'future', 'is', 'unlikely', '.', 'This', 'enormous', 'diversity', 'among', 'insects', 'also', 'means', 'that', 'they', 'have', 'very', 'different', 'life', 'histories', 'and', 'roles', 'in', 'the', 'ecosystems', '.', 'For', 'instance', ',', 'a', 'hoverfly', 'in', 'Greenland', 'lives', 'a', 'very', 'different', 'life', 'than', 'a', 'mantid', 'in', 'the', 'Brazilian', 'rainforest', '.', 'But', 'even', 'within', 'each', 'of', 'these', 'two', 'groups', ',', 'numerous', 'species', 'exist', 'each', 'with', 'their', 'own', 'special', 'characteristics', 'and', 'ecological', 'roles', '.', 'To', 'examine', 'the', 'biology', 'of', 'each', 'species', 'and', 'its', 'interactions', 'with', 'other', 'species', ',', 'it', 'is', 'necessary', 'to', 'catch', ',', 'identify', ',', 'and', 'count', 'a', 'lot', 'of', 'insects', '.', 'It', 'goes', 'without', 'saying', 'that', 'this', 'is', 'a', 'very', 'time-consuming', 'process', ',', 'which', 'to', 'a', 'large', 'degree', ',', 'has', 'constrained', 'the', 'ability', 'of', 'scientists', 'to', 'gain', 'insights', 'into', 'how', 'external', 'factors', 'shape', 'the', 'life', 'of', 'insects', '.', 'A', 'new', 'study', 'published', 'in', 'the', 'Proceedings', 'of', 'the', 'National', 'Academy', 'of', 'Sciences', 'shows', 'how', 'advanced', 'computer', 'technology', 'and', 'artificial', 'intelligence', 'quickly', 'and', 'efficiently', 'can', 'identify', 'and', 'count', 'insects', '.', 'It', 'is', 'a', 'huge', 'step', 'forward', 'for', 'the', 'scientists', 'to', 'be', 'able', 'to', 'understand', 'how', 'this', 'important', 'group', 'of', 'animals', 'changes', 'through', 'time', '--', 'for', 'example', 'in', 'response', 'to', 'loss', 'of', 'habitat', 'and', 'climate', 'change', '.', 'Deep', 'Learning', \"''\", 'With', 'the', 'help', 'of', 'advanced', 'camera', 'technology', ',', 'we', 'can', 'now', 'collect', 'millions', 'of', 'photos', 'at', 'our', 'field', 'sites', '.', 'When', 'we', ',', 'at', 'the', 'same', 'time', ',', 'teach', 'the', 'computer', 'to', 'tell', 'the', 'different', 'species', 'apart', ',', 'the', 'computer', 'can', 'quickly', 'identify', 'the', 'different', 'species', 'in', 'the', 'images', 'and', 'count', 'how', 'many', 'it', 'found', 'of', 'each', 'of', 'them', '.', 'It', 'is', 'a', 'game-changer', 'compared', 'to', 'having', 'a', 'person', 'with', 'binoculars', 'in', 'the', 'field', 'or', 'in', 'front', 'of', 'the', 'microscope', 'in', 'the', 'lab', 'who', 'manually', 'identifies', 'and', 'counts', 'the', 'animals', ',', \"''\", 'explains', 'senior', 'scientist', 'Toke', 'T.', 'Høye', 'from', 'Department', 'of', 'Bioscience', 'and', 'Arctic', 'Research', 'Centre', 'at', 'Aarhus', 'University', ',', 'who', 'headed', 'the', 'new', 'study', '.', 'The', 'international', 'team', 'behind', 'the', 'study', 'included', 'biologists', ',', 'statisticians', ',', 'and', 'mechanical', ',', 'electrical', 'and', 'software', 'engineers', '.', 'The', 'methods', 'described', 'in', 'the', 'paper', 'go', 'by', 'the', 'umbrella', 'term', 'deep', 'learning', 'and', 'are', 'forms', 'of', 'artificial', 'intelligence', 'mostly', 'used', 'in', 'other', 'areas', 'of', 'research', 'such', 'as', 'in', 'the', 'development', 'of', 'driverless', 'cars', '.', 'But', 'now', 'the', 'researchers', 'have', 'demonstrated', 'how', 'the', 'technology', 'can', 'be', 'an', 'alternative', 'to', 'the', 'laborious', 'task', 'of', 'manually', 'observing', 'insects', 'in', 'their', 'natural', 'environment', 'as', 'well', 'as', 'the', 'tasks', 'of', 'sorting', 'and', 'identifying', 'insect', 'samples', '.', '``', 'We', 'can', 'use', 'the', 'deep', 'learning', 'to', 'find', 'the', 'needle', 'in', 'the', 'hay', 'stack', 'so', 'to', 'speak', '--', 'the', 'specimen', 'of', 'a', 'rare', 'or', 'undescribed', 'species', 'among', 'all', 'the', 'specimens', 'of', 'widespread', 'and', 'common', 'species', '.', 'In', 'the', 'future', ',', 'all', 'the', 'trivial', 'work', 'can', 'be', 'done', 'by', 'the', 'computer', 'and', 'we', 'can', 'focus', 'on', 'the', 'most', 'demanding', 'tasks', ',', 'such', 'as', 'describing', 'new', 'species', ',', 'which', 'until', 'now', 'was', 'unknown', 'to', 'the', 'computer', ',', 'and', 'to', 'interpret', 'the', 'wealth', 'of', 'new', 'results', 'we', 'will', 'have', \"''\", 'explains', 'Toke', 'T.', 'Høye', '.', 'And', 'there', 'is', 'indeed', 'many', 'tasks', 'ahead', ',', 'when', 'it', 'comes', 'to', 'research', 'on', 'insects', 'and', 'other', 'invertebrates', ',', 'called', 'entomology', '.', 'One', 'thing', 'is', 'the', 'lack', 'of', 'good', 'databases', 'to', 'compare', 'unknown', 'species', 'to', 'those', 'which', 'have', 'already', 'been', 'described', ',', 'but', 'also', 'because', 'a', 'proportionally', 'larger', 'share', 'of', 'researchers', 'concentrate', 'on', 'well-known', 'species', 'like', 'birds', 'and', 'mammals', '.', 'With', 'deep', 'learning', ',', 'the', 'researchers', 'expect', 'to', 'be', 'able', 'to', 'rapidly', 'advance', 'knowledge', 'about', 'insects', 'considerably', '.', 'Long', 'time', 'series', 'are', 'necessary', 'To', 'understand', 'how', 'insect', 'populations', 'change', 'through', 'time', ',', 'observations', 'need', 'to', 'be', 'made', 'in', 'the', 'same', 'place', 'and', 'in', 'the', 'same', 'way', 'over', 'a', 'long', 'time', '.', 'It', 'is', 'necessary', 'with', 'long', 'time', 'series', 'of', 'data', '.', 'Some', 'species', 'become', 'more', 'numerous', 'and', 'others', 'more', 'rare', ',', 'but', 'to', 'understand', 'the', 'mechanisms', 'that', 'causes', 'these', 'changes', ',', 'it', 'is', 'critical', 'that', 'the', 'same', 'observations', 'are', 'made', 'year', 'after', 'year', '.', 'An', 'easy', 'method', 'is', 'to', 'mount', 'cameras', 'in', 'the', 'same', 'location', 'and', 'take', 'pictures', 'of', 'the', 'same', 'local', 'area', '.', 'For', 'instance', ',', 'cameras', 'can', 'take', 'a', 'picture', 'every', 'minute', '.', 'This', 'will', 'give', 'piles', 'of', 'data', ',', 'which', 'over', 'the', 'years', 'can', 'inform', 'about', 'how', 'insects', 'respond', 'to', 'warmer', 'climates', 'or', 'to', 'the', 'changes', 'caused', 'by', 'land', 'management', '.', 'Such', 'data', 'can', 'become', 'an', 'important', 'tool', 'to', 'ensure', 'a', 'proper', 'balance', 'between', 'human', 'use', 'and', 'protection', 'of', 'natural', 'resources', '.', '``', 'There', 'are', 'still', 'challenges', 'ahead', 'before', 'these', 'new', 'methods', 'can', 'become', 'widely', 'available', ',', 'but', 'our', 'study', 'points', 'to', 'a', 'number', 'of', 'results', 'from', 'other', 'research', 'disciplines', ',', 'which', 'can', 'help', 'solve', 'the', 'challenges', 'for', 'entomology', '.', 'Here', ',', 'a', 'close', 'interdisciplinary', 'collaboration', 'among', 'biologists', 'and', 'engineers', 'is', 'critical', ',', \"''\", 'says', 'Toke', 'T.', 'Høye', '.']\n","['Using', 'light', 'to', 'revolutionize', 'artificial', 'intelligence', 'An', 'international', 'team', 'of', 'researchers', ',', 'including', 'Professor', 'Roberto', 'Morandotti', 'of', 'the', 'Institut', 'national', 'de', 'la', 'recherche', 'scientifique', '(', 'INRS', ')', ',', 'just', 'introduced', 'a', 'new', 'photonic', 'processor', 'that', 'could', 'revolutionize', 'artificial', 'intelligence', ',', 'as', 'reported', 'by', 'the', 'journal', 'Nature', '.', 'Artificial', 'neural', 'networks', ',', 'layers', 'of', 'interconnected', 'artificial', 'neurons', ',', 'are', 'of', 'great', 'interest', 'for', 'machine', 'learning', 'tasks', 'such', 'as', 'speech', 'recognition', 'and', 'medical', 'diagnosis', '.', 'Actually', ',', 'electronic', 'computing', 'hardware', 'are', 'nearing', 'the', 'limit', 'of', 'their', 'capabilities', ',', 'yet', 'the', 'demand', 'for', 'greater', 'computing', 'power', 'is', 'constantly', 'growing', '.', 'Researchers', 'turned', 'themselves', 'to', 'photons', 'instead', 'of', 'electrons', 'to', 'carry', 'information', 'at', 'the', 'speed', 'of', 'light', '.', 'In', 'fact', ',', 'not', 'only', 'photons', 'can', 'process', 'information', 'much', 'faster', 'than', 'electrons', ',', 'but', 'they', 'are', 'the', 'basis', 'of', 'the', 'current', 'Internet', ',', 'where', 'it', 'is', 'important', 'to', 'avoid', 'the', 'so-called', 'electronic', 'bottleneck', '(', 'conversion', 'of', 'an', 'optical', 'signal', 'into', 'an', 'electronic', 'signal', ',', 'and', 'vice', 'versa', ')', '.', 'Increased', 'Computing', 'Speed', 'The', 'proposed', 'optical', 'neural', 'network', 'is', 'capable', 'of', 'recognizing', 'and', 'processing', 'large-scale', 'data', 'and', 'images', 'at', 'ultra-high', 'computing', 'speeds', ',', 'beyond', 'ten', 'trillion', 'operations', 'per', 'second', '.', 'Professor', 'Morandotti', ',', 'an', 'expert', 'in', 'integrated', 'photonics', ',', 'explains', 'how', 'an', 'optical', 'frequency', 'comb', ',', 'a', 'light', 'source', 'comprised', 'of', 'many', 'equally', 'spaced', 'frequency', 'modes', ',', 'was', 'integrated', 'into', 'a', 'computer', 'chip', 'and', 'used', 'as', 'a', 'power-efficient', 'source', 'for', 'optical', 'computing', '.', 'This', 'device', 'performs', 'a', 'type', 'of', 'matrix-vector', 'multiplication', 'known', 'as', 'a', 'convolution', 'for', 'image-processing', 'applications', '.', 'It', 'shows', 'promising', 'results', 'for', 'real-time', 'massive-data', 'machine', 'learning', 'tasks', ',', 'such', 'as', 'identifying', 'faces', 'in', 'cameras', 'or', 'pathology', 'identification', 'in', 'clinical', 'scanning', 'applications', '.', 'Their', 'approach', 'is', 'scalable', 'and', 'trainable', 'to', 'much', 'more', 'complex', 'networks', 'for', 'demanding', 'applications', 'such', 'as', 'unmanned', 'vehicles', 'and', 'real-time', 'video', 'recognition', ',', 'allowing', ',', 'in', 'a', 'not-so-far', 'future', ',', 'a', 'full', 'integration', 'with', 'the', 'up-and-coming', 'Internet', 'of', 'Things', '.']\n","['Robot', 'displays', 'a', 'glimmer', 'of', 'empathy', 'to', 'a', 'partner', 'robot', 'Like', 'a', 'longtime', 'couple', 'who', 'can', 'predict', 'each', 'other', \"'s\", 'every', 'move', ',', 'a', 'Columbia', 'Engineering', 'robot', 'has', 'learned', 'to', 'predict', 'its', 'partner', 'robot', \"'s\", 'future', 'actions', 'and', 'goals', 'based', 'on', 'just', 'a', 'few', 'initial', 'video', 'frames', '.', 'When', 'two', 'primates', 'are', 'cooped', 'up', 'together', 'for', 'a', 'long', 'time', ',', 'we', 'quickly', 'learn', 'to', 'predict', 'the', 'near-term', 'actions', 'of', 'our', 'roommates', ',', 'co-workers', 'or', 'family', 'members', '.', 'Our', 'ability', 'to', 'anticipate', 'the', 'actions', 'of', 'others', 'makes', 'it', 'easier', 'for', 'us', 'to', 'successfully', 'live', 'and', 'work', 'together', '.', 'In', 'contrast', ',', 'even', 'the', 'most', 'intelligent', 'and', 'advanced', 'robots', 'have', 'remained', 'notoriously', 'inept', 'at', 'this', 'sort', 'of', 'social', 'communication', '.', 'This', 'may', 'be', 'about', 'to', 'change', '.', 'The', 'study', ',', 'conducted', 'at', 'Columbia', 'Engineering', \"'s\", 'Creative', 'Machines', 'Lab', 'led', 'by', 'Mechanical', 'Engineering', 'Professor', 'Hod', 'Lipson', ',', 'is', 'part', 'of', 'a', 'broader', 'effort', 'to', 'endow', 'robots', 'with', 'the', 'ability', 'to', 'understand', 'and', 'anticipate', 'the', 'goals', 'of', 'other', 'robots', ',', 'purely', 'from', 'visual', 'observations', '.', 'The', 'researchers', 'first', 'built', 'a', 'robot', 'and', 'placed', 'it', 'in', 'a', 'playpen', 'roughly', '3x2', 'feet', 'in', 'size', '.', 'They', 'programmed', 'the', 'robot', 'to', 'seek', 'and', 'move', 'towards', 'any', 'green', 'circle', 'it', 'could', 'see', '.', 'But', 'there', 'was', 'a', 'catch', ':', 'Sometimes', 'the', 'robot', 'could', 'see', 'a', 'green', 'circle', 'in', 'its', 'camera', 'and', 'move', 'directly', 'towards', 'it', '.', 'But', 'other', 'times', ',', 'the', 'green', 'circle', 'would', 'be', 'occluded', 'by', 'a', 'tall', 'red', 'carboard', 'box', ',', 'in', 'which', 'case', 'the', 'robot', 'would', 'move', 'towards', 'a', 'different', 'green', 'circle', ',', 'or', 'not', 'at', 'all', '.', 'After', 'observing', 'its', 'partner', 'puttering', 'around', 'for', 'two', 'hours', ',', 'the', 'observing', 'robot', 'began', 'to', 'anticipate', 'its', 'partner', \"'s\", 'goal', 'and', 'path', '.', 'The', 'observing', 'robot', 'was', 'eventually', 'able', 'to', 'predict', 'its', 'partner', \"'s\", 'goal', 'and', 'path', '98', 'out', 'of', '100', 'times', ',', 'across', 'varying', 'situations', '--', 'without', 'being', 'told', 'explicitly', 'about', 'the', 'partner', \"'s\", 'visibility', 'handicap', '.', '``', 'Our', 'initial', 'results', 'are', 'very', 'exciting', ',', \"''\", 'says', 'Boyuan', 'Chen', ',', 'lead', 'author', 'of', 'the', 'study', ',', 'which', 'was', 'conducted', 'in', 'collaboration', 'with', 'Carl', 'Vondrick', ',', 'assistant', 'professor', 'of', 'computer', 'science', ',', 'and', 'published', 'today', 'by', 'Nature', 'Scientific', 'Reports', '.', '``', 'Our', 'findings', 'begin', 'to', 'demonstrate', 'how', 'robots', 'can', 'see', 'the', 'world', 'from', 'another', 'robot', \"'s\", 'perspective', '.', 'The', 'ability', 'of', 'the', 'observer', 'to', 'put', 'itself', 'in', 'its', 'partner', \"'s\", 'shoes', ',', 'so', 'to', 'speak', ',', 'and', 'understand', ',', 'without', 'being', 'guided', ',', 'whether', 'its', 'partner', 'could', 'or', 'could', 'not', 'see', 'the', 'green', 'circle', 'from', 'its', 'vantage', 'point', ',', 'is', 'perhaps', 'a', 'primitive', 'form', 'of', 'empathy', '.', \"''\", 'When', 'they', 'designed', 'the', 'experiment', ',', 'the', 'researchers', 'expected', 'that', 'the', 'Observer', 'Robot', 'would', 'learn', 'to', 'make', 'predictions', 'about', 'the', 'Subject', 'Robot', \"'s\", 'near-term', 'actions', '.', 'What', 'the', 'researchers', 'did', \"n't\", 'expect', ',', 'however', ',', 'was', 'how', 'accurately', 'the', 'Observer', 'Robot', 'could', 'foresee', 'its', 'colleague', \"'s\", 'future', '``', 'moves', \"''\", 'with', 'only', 'a', 'few', 'seconds', 'of', 'video', 'as', 'a', 'cue', '.', 'The', 'researchers', 'acknowledge', 'that', 'the', 'behaviors', 'exhibited', 'by', 'the', 'robot', 'in', 'this', 'study', 'are', 'far', 'simpler', 'than', 'the', 'behaviors', 'and', 'goals', 'of', 'humans', '.', 'They', 'believe', ',', 'however', ',', 'that', 'this', 'may', 'be', 'the', 'beginning', 'of', 'endowing', 'robots', 'with', 'what', 'cognitive', 'scientists', 'call', '``', 'Theory', 'of', 'Mind', \"''\", '(', 'ToM', ')', '.', 'At', 'about', 'age', 'three', ',', 'children', 'begin', 'to', 'understand', 'that', 'others', 'may', 'have', 'different', 'goals', ',', 'needs', 'and', 'perspectives', 'than', 'they', 'do', '.', 'This', 'can', 'lead', 'to', 'playful', 'activities', 'such', 'as', 'hide', 'and', 'seek', ',', 'as', 'well', 'as', 'more', 'sophisticated', 'manipulations', 'like', 'lying', '.', 'More', 'broadly', ',', 'ToM', 'is', 'recognized', 'as', 'a', 'key', 'distinguishing', 'hallmark', 'of', 'human', 'and', 'primate', 'cognition', ',', 'and', 'a', 'factor', 'that', 'is', 'essential', 'for', 'complex', 'and', 'adaptive', 'social', 'interactions', 'such', 'as', 'cooperation', ',', 'competition', ',', 'empathy', ',', 'and', 'deception', '.', 'In', 'addition', ',', 'humans', 'are', 'still', 'better', 'than', 'robots', 'at', 'describing', 'their', 'predictions', 'using', 'verbal', 'language', '.', 'The', 'researchers', 'had', 'the', 'observing', 'robot', 'make', 'its', 'predictions', 'in', 'the', 'form', 'of', 'images', ',', 'rather', 'than', 'words', ',', 'in', 'order', 'to', 'avoid', 'becoming', 'entangled', 'in', 'the', 'thorny', 'challenges', 'of', 'human', 'language', '.', 'Yet', ',', 'Lipson', 'speculates', ',', 'the', 'ability', 'of', 'a', 'robot', 'to', 'predict', 'the', 'future', 'actions', 'visually', 'is', 'not', 'unique', ':', '``', 'We', 'humans', 'also', 'think', 'visually', 'sometimes', '.', 'We', 'frequently', 'imagine', 'the', 'future', 'in', 'our', 'mind', \"'s\", 'eyes', ',', 'not', 'in', 'words', '.', \"''\", 'Lipson', 'acknowledges', 'that', 'there', 'are', 'many', 'ethical', 'questions', '.', 'The', 'technology', 'will', 'make', 'robots', 'more', 'resilient', 'and', 'useful', ',', 'but', 'when', 'robots', 'can', 'anticipate', 'how', 'humans', 'think', ',', 'they', 'may', 'also', 'learn', 'to', 'manipulate', 'those', 'thoughts', '.', '``', 'We', 'recognize', 'that', 'robots', 'are', \"n't\", 'going', 'to', 'remain', 'passive', 'instruction-following', 'machines', 'for', 'long', ',', \"''\", 'Lipson', 'says', '.', '``', 'Like', 'other', 'forms', 'of', 'advanced', 'AI', ',', 'we', 'hope', 'that', 'policymakers', 'can', 'help', 'keep', 'this', 'kind', 'of', 'technology', 'in', 'check', ',', 'so', 'that', 'we', 'can', 'all', 'benefit', '.', \"''\"]\n","['A', 'robotic', 'revolution', 'for', 'urban', 'nature', 'Drones', ',', 'robots', 'and', 'autonomous', 'systems', 'can', 'transform', 'the', 'natural', 'world', 'in', 'and', 'around', 'cities', 'for', 'people', 'and', 'wildlife', '.', 'International', 'research', ',', 'involving', 'over', '170', 'experts', 'and', 'led', 'by', 'the', 'University', 'of', 'Leeds', ',', 'assessed', 'the', 'opportunities', 'and', 'challenges', 'that', 'this', 'cutting-edge', 'technology', 'could', 'have', 'for', 'urban', 'nature', 'and', 'green', 'spaces', '.', 'The', 'researchers', 'highlighted', 'opportunities', 'to', 'improve', 'how', 'we', 'monitor', 'nature', ',', 'such', 'as', 'identifying', 'emerging', 'pests', 'and', 'ensuring', 'plants', 'are', 'cared', 'for', ',', 'and', 'helping', 'people', 'engage', 'with', 'and', 'appreciate', 'the', 'natural', 'world', 'around', 'them', '.', 'As', 'robotics', ',', 'autonomous', 'vehicles', 'and', 'drones', 'become', 'more', 'widely', 'used', 'across', 'cities', ',', 'pollution', 'and', 'traffic', 'congestion', 'may', 'reduce', ',', 'making', 'towns', 'and', 'cities', 'more', 'pleasant', 'places', 'to', 'spend', 'time', 'outside', '.', 'But', 'the', 'researchers', 'also', 'warned', 'that', 'advances', 'in', 'robotics', 'and', 'automation', 'could', 'be', 'damaging', 'to', 'the', 'environment', '.', 'For', 'instance', ',', 'robots', 'and', 'drones', 'might', 'generate', 'new', 'sources', 'of', 'waste', 'and', 'pollution', 'themselves', ',', 'with', 'potentially', 'substantial', 'negative', 'implications', 'for', 'urban', 'nature', '.', 'Cities', 'might', 'have', 'to', 'be', 're-planned', 'to', 'provide', 'enough', 'room', 'for', 'robots', 'and', 'drones', 'to', 'operate', ',', 'potentially', 'leading', 'to', 'a', 'loss', 'of', 'green', 'space', '.', 'And', 'they', 'could', 'also', 'increase', 'existing', 'social', 'inequalities', ',', 'such', 'as', 'unequal', 'access', 'to', 'green', 'space', '.', 'Lead', 'author', 'Dr', 'Martin', 'Dallimer', ',', 'from', 'the', 'School', 'of', 'Earth', 'and', 'Environment', 'at', 'the', 'University', 'of', 'Leeds', ',', 'said', ':', '``', 'Technology', ',', 'such', 'as', 'robotics', ',', 'has', 'the', 'potential', 'to', 'change', 'almost', 'every', 'aspect', 'of', 'our', 'lives', '.', 'As', 'a', 'society', ',', 'it', 'is', 'vital', 'that', 'we', 'proactively', 'try', 'to', 'understand', 'any', 'possible', 'side', 'effects', 'and', 'risks', 'of', 'our', 'growing', 'use', 'of', 'robots', 'and', 'automated', 'systems', '.', '``', 'Although', 'the', 'future', 'impacts', 'on', 'urban', 'green', 'spaces', 'and', 'nature', 'are', 'hard', 'to', 'predict', ',', 'we', 'need', 'to', 'make', 'sure', 'that', 'the', 'public', ',', 'policy', 'makers', 'and', 'robotics', 'developers', 'are', 'aware', 'of', 'the', 'potential', 'pros', 'and', 'cons', ',', 'so', 'we', 'can', 'avoid', 'detrimental', 'consequences', 'and', 'fully', 'realise', 'the', 'benefits', '.', \"''\", 'The', 'research', ',', 'published', 'today', 'in', 'Nature', 'Ecology', '&', 'Evolution', ',', 'is', 'authored', 'by', 'a', 'team', 'of', '77', 'academics', 'and', 'practitioners', '.', 'The', 'researchers', 'conducted', 'an', 'online', 'survey', 'of', '170', 'experts', 'from', '35', 'countries', ',', 'which', 'they', 'say', 'provides', 'a', 'current', 'best', 'guess', 'of', 'what', 'the', 'future', 'could', 'hold', '.', 'Participants', 'gave', 'their', 'views', 'on', 'the', 'potential', 'opportunities', 'and', 'challenges', 'for', 'urban', 'biodiversity', 'and', 'ecosystems', ',', 'from', 'the', 'growing', 'use', 'of', 'robotics', 'and', 'autonomous', 'systems', '.', 'These', 'are', 'defined', 'as', 'technologies', 'that', 'can', 'sense', ',', 'analyse', ',', 'interact', 'with', 'and', 'manipulate', 'their', 'physical', 'environment', '.', 'This', 'includes', 'unmanned', 'aerial', 'vehicles', '(', 'drones', ')', ',', 'self-driving', 'cars', ',', 'robots', 'able', 'to', 'repair', 'infrastructure', ',', 'and', 'wireless', 'sensor', 'networks', 'used', 'for', 'monitoring', '.', 'These', 'technologies', 'have', 'a', 'large', 'range', 'of', 'potential', 'applications', ',', 'such', 'as', 'autonomous', 'transport', ',', 'waste', 'collection', ',', 'infrastructure', 'maintenance', 'and', 'repair', ',', 'policing', 'and', 'precision', 'agriculture', '.', 'The', 'research', 'was', 'conducted', 'as', 'part', 'of', 'Leeds', \"'\", 'Self', 'Repairing', 'Cities', 'project', ',', 'which', 'aims', 'to', 'enable', 'robots', 'and', 'autonomous', 'systems', 'to', 'maintain', 'urban', 'infrastructure', 'without', 'causing', 'disruption', 'to', 'citizens', '.', 'First', 'author', 'Dr', 'Mark', 'Goddard', 'conducted', 'the', 'work', 'whilst', 'at', 'the', 'University', 'of', 'Leeds', 'and', 'is', 'now', 'based', 'at', 'the', 'Northumbria', 'University', '.', 'He', 'said', ':', '``', 'Spending', 'time', 'in', 'urban', 'green', 'spaces', 'and', 'interacting', 'with', 'nature', 'brings', 'a', 'range', 'of', 'human', 'health', 'and', 'well-being', 'benefits', ',', 'and', 'robots', 'are', 'likely', 'to', 'transform', 'many', 'of', 'the', 'ways', 'in', 'which', 'we', 'experience', 'and', 'gain', 'benefits', 'from', 'urban', 'nature', '.', '``', 'Understanding', 'how', 'robotics', 'and', 'autonomous', 'systems', 'will', 'affect', 'our', 'interaction', 'with', 'nature', 'is', 'vital', 'for', 'ensuring', 'that', 'our', 'future', 'cities', 'support', 'wildlife', 'that', 'is', 'accessible', 'to', 'all', '.', \"''\"]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vf2X0K125XHx"},"source":["3.) Lemmatize and lower arrays of words"]},{"cell_type":"code","metadata":{"id":"CgKf7rri5Ug_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622564033865,"user_tz":-120,"elapsed":1638,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}},"outputId":"a0e94c4c-033a-4dc4-b8d7-c8a1f40beffa"},"source":["# initialize lemmatizer \n","lemmatizer = WordNetLemmatizer();\n","\n","# create WordNetLemmatizer object \n","wnl = WordNetLemmatizer() \n","\n","print(lemmatizer.lemmatize(\"cars\", \"v\"));\n","\n","# lower and lemmatize Text1\n","i = 0\n","while i < len(tokenized_word1):\n","    tokenized_word1[i] = tokenized_word1[i].lower();\n","    tokenized_word1[i] = lemmatizer.lemmatize(tokenized_word1[i], \"v\");\n","    i += 1\n","\n","# lower and lemmatize Text2\n","i = 0\n","while i < len(tokenized_word2):\n","    tokenized_word2[i] = tokenized_word2[i].lower();\n","    tokenized_word2[i] = lemmatizer.lemmatize(tokenized_word2[i], \"v\");\n","    i += 1\n","\n","# lower and lemmatize Text3\n","i = 0\n","while i < len(tokenized_word3):\n","    tokenized_word3[i] = tokenized_word3[i].lower();\n","    tokenized_word3[i] = lemmatizer.lemmatize(tokenized_word3[i], \"v\");\n","    i += 1\n","\n","# lower and lemmatize Text4\n","i = 0\n","while i < len(tokenized_word4):\n","    tokenized_word4[i] = tokenized_word4[i].lower();\n","    tokenized_word4[i] = lemmatizer.lemmatize(tokenized_word4[i], \"v\");\n","    i += 1\n","\n","# lower and lemmatize Text5\n","i = 0\n","while i < len(tokenized_word5):\n","    tokenized_word5[i] = tokenized_word5[i].lower();\n","    tokenized_word5[i] = lemmatizer.lemmatize(tokenized_word5[i], \"v\");\n","    i += 1"],"execution_count":4,"outputs":[{"output_type":"stream","text":["cars\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z2eZFZsw5spd"},"source":["4.) Create a Vectorizer Object with dictionary"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6qeU0PD6Lr6","executionInfo":{"status":"ok","timestamp":1622564033866,"user_tz":-120,"elapsed":14,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}},"outputId":"3d36f936-1b68-4841-ad9a-199e01764f90"},"source":["# join lemmatized words to strings\n","lemmatized_string1 = ' '.join([wnl.lemmatize(words) for words in tokenized_word1]) \n","lemmatized_string2 = ' '.join([wnl.lemmatize(words) for words in tokenized_word2])\n","lemmatized_string3 = ' '.join([wnl.lemmatize(words) for words in tokenized_word3])\n","lemmatized_string4 = ' '.join([wnl.lemmatize(words) for words in tokenized_word4])\n","lemmatized_string5 = ' '.join([wnl.lemmatize(words) for words in tokenized_word5]) \n","\n","# add lemmatized strings to document\n","document = [lemmatized_string1, \n","            lemmatized_string2,\n","            lemmatized_string3,\n","            lemmatized_string4,\n","            lemmatized_string5] \n","  \n","# create a Vectorizer Object \n","vectorizer = CountVectorizer().fit(document) \n","  \n","# printing the identified Unique words along with their indices \n","dic = vectorizer.vocabulary_\n","print(\"Vocabulary: \", dic) \n","  \n","# encode the Document \n","vector = vectorizer.transform(document) \n","  \n","# transform to numpy array\n","arr = np.array(vector.toarray())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Vocabulary:  {'how': 402, 'to': 863, 'train': 877, 'robot': 730, 'use': 902, 'ai': 37, 'and': 53, 'supercomputer': 821, 'before': 90, 'he': 385, 'join': 459, 'the': 845, 'university': 894, 'of': 584, 'texas': 841, 'at': 72, 'arlington': 64, 'an': 51, 'assistant': 71, 'professor': 669, 'in': 418, 'department': 230, 'computer': 181, 'science': 748, 'engineer': 284, 'found': 340, 'robotic': 731, 'vision': 920, 'laboratory': 471, 'there': 851, 'william': 946, 'beksi': 95, 'intern': 447, 'irobot': 455, 'world': 954, 'largest': 478, 'producer': 668, 'consumer': 192, 'mainly': 505, 'through': 861, 'it': 457, 'roomba': 736, 'vacuum': 906, 'navigate': 558, 'build': 117, 'environment': 290, 'must': 553, 'be': 87, 'able': 14, 'sense': 758, 'make': 508, 'decision': 223, 'about': 15, 'interact': 442, 'with': 948, 'their': 846, 'locale': 496, 'researcher': 719, 'company': 173, 'interest': 446, 'machine': 504, 'deep': 224, 'learn': 482, 'object': 579, 'but': 118, 'do': 257, 'so': 784, 'require': 717, 'large': 476, 'dataset': 219, 'image': 412, 'while': 938, 'million': 535, 'photo': 625, 'video': 917, 'room': 735, 'none': 570, 'shoot': 766, 'from': 346, 'vantage': 907, 'point': 640, 'effort': 275, 'human': 405, 'centric': 137, 'perspective': 621, 'fail': 322, 'research': 718, 'focus': 331, 'on': 585, 'robotics': 732, 'cyber': 213, 'physical': 631, 'system': 828, 'particular': 608, 'develop': 238, 'algorithm': 41, 'that': 844, 'enable': 281, 'interaction': 443, 'autonomously': 78, 'acquire': 22, 'skill': 779, 'necessary': 560, 'execute': 304, 'high': 392, 'level': 485, 'task': 833, 'say': 742, 'year': 956, 'later': 479, 'now': 576, 'group': 373, 'include': 419, 'six': 777, 'phd': 624, 'student': 813, 'recall': 704, 'problem': 662, 'begin': 91, 'explore': 314, 'solution': 789, 'manual': 515, 'approach': 61, 'by': 119, 'some': 791, 'involve': 454, 'expensive': 308, '360': 6, 'degree': 226, 'camera': 123, 'capture': 127, 'rent': 714, 'airbnb': 39, 'house': 400, 'custom': 211, 'software': 788, 'stitch': 810, 'back': 82, 'into': 451, 'whole': 941, 'believe': 96, 'method': 531, 'would': 955, 'too': 868, 'slow': 781, 'succeed': 818, 'instead': 434, 'look': 500, 'form': 337, 'know': 465, 'generative': 357, 'adversarial': 30, 'network': 564, 'or': 595, 'gans': 353, 'where': 935, 'two': 885, 'neural': 565, 'contest': 194, 'each': 264, 'other': 597, 'game': 352, 'until': 899, 'generator': 358, 'new': 567, 'data': 217, 'can': 124, 'fool': 333, 'discriminator': 249, 'once': 586, 'such': 820, 'creation': 206, 'infinite': 425, 'number': 577, 'possible': 648, 'outdoor': 601, 'different': 244, 'kind': 464, 'chair': 138, 'table': 829, 'vehicle': 911, 'slightly': 780, 'still': 809, 'person': 620, 'identifiable': 408, 'recognizable': 707, 'dimension': 245, 'characteristic': 142, 'you': 958, 'perturb': 622, 'these': 852, 'move': 549, 'them': 847, 'position': 646, 'light': 488, 'color': 165, 'texture': 842, 'then': 849, 'render': 713, 'could': 201, 'explain': 312, 'this': 856, 'potentially': 650, 'provide': 679, 'limitless': 492, 'manually': 516, 'design': 234, 'take': 831, 'huge': 404, 'amount': 50, 'resource': 722, 'hour': 399, 'labor': 470, 'if': 411, 'properly': 675, 'second': 753, 'mohammad': 541, 'samiul': 740, 'arshad': 67, 'graduate': 367, 'generate': 355, 'for': 335, 'synthetic': 827, 'scene': 746, 'after': 33, 'initial': 429, 'attempt': 73, 'realize': 702, 'his': 394, 'dream': 260, 'create': 205, 'photorealistic': 629, 'full': 348, 'presently': 657, 'out': 600, 'reach': 698, 'we': 930, 'step': 808, 'current': 210, 'determine': 236, 'start': 806, 'smaller': 783, 'scale': 744, 'simple': 772, 'present': 656, 'pcgan': 613, 'first': 330, 'conditional': 184, 'dense': 229, 'cloud': 155, 'unsupervised': 898, 'mode': 539, 'international': 448, 'conference': 186, '3d': 7, '3dv': 8, 'nov': 575, '2020': 4, 'paper': 605, 'progressive': 671, 'show': 767, 'capable': 126, 'set': 761, 'derive': 232, 'shapenetcore': 763, 'cad': 120, 'model': 540, 'database': 218, 'mimic': 536, 'distribution': 254, 'produce': 667, 'fine': 329, 'detail': 235, 'multiple': 551, 'resolution': 721, 'work': 952, 'datasets': 220, 'no': 569, 'one': 587, 'yet': 957, 'handle': 380, 'order': 596, 'test': 840, 'diversity': 256, 'shape': 762, 'team': 835, 'choose': 147, 'sofa': 787, 'airplane': 40, 'motorcycle': 547, 'experiment': 310, 'tool': 869, 'allow': 43, 'access': 18, 'near': 559, 'version': 914, 'our': 599, 'basic': 85, 'structure': 812, 'low': 503, 'gradually': 366, 'up': 900, 'towards': 872, 'relationship': 711, 'between': 100, 'part': 606, 'example': 302, 'leg': 484, 'same': 739, 'seat': 752, 'top': 870, 'contrast': 195, 'also': 46, 're': 697, 'small': 782, 'hierarchy': 391, 'generation': 356, 'extremely': 317, 'useful': 903, 'they': 853, '000': 0, 'random': 691, 'sample': 741, 'class': 151, 'perform': 617, 'evaluation': 296, 'evaluate': 295, 'both': 109, 'geometry': 359, 'variety': 908, 'common': 171, 'metric': 532, 'field': 327, 'result': 725, 'synthesize': 826, 'quality': 686, 'disparate': 250, 'array': 66, 'sim2real': 771, 'another': 55, 'issue': 456, 'colloquially': 164, 'have': 383, 'real': 699, 'subtle': 817, 'difference': 243, 'quantify': 687, 'those': 858, 'simulation': 774, 'more': 544, 'realistic': 701, 'physic': 630, 'friction': 345, 'collision': 163, 'gravity': 368, 'ray': 696, 'photon': 626, 'trace': 874, 'next': 568, 'deploy': 231, 'see': 754, 'sim': 770, 'domain': 258, 'gap': 354, 'tacc': 830, 'maverick': 523, 'which': 937, 'cyberinfrastructure': 214, 'utrc': 905, 'program': 670, 'compute': 180, 'any': 57, 'ut': 904, '14': 2, 'institution': 436, 'want': 925, 'increase': 420, 'come': 169, 'computational': 179, 'cost': 200, 'note': 573, 'hardware': 382, 'my': 554, 'lab': 469, 'essential': 293, 'addition': 28, 'computation': 178, 'need': 561, 'extensive': 315, 'storage': 811, 'especially': 292, 'hundred': 406, 'megabyte': 529, 'per': 615, 'around': 65, 'enormous': 285, 'long': 498, 'way': 929, 'really': 703, 'good': 365, 'robust': 733, 'autonomous': 77, 'period': 619, 'time': 862, 'benefit': 97, 'health': 387, 'care': 130, 'manufacture': 517, 'agriculture': 35, 'publication': 681, 'just': 461, 'toward': 871, 'ultimate': 887, 'goal': 363, 'indoor': 422, 'advance': 29, 'perception': 616, 'capability': 125, 'artificial': 68, 'intelligence': 440, 'put': 684, 'life': 487, 'insect': 431, 'scientist': 751, 'combine': 168, 'technology': 836, 'biological': 104, 'identify': 410, 'supernatural': 822, 'speed': 803, 'open': 590, 'possibility': 647, 'describe': 233, 'unknown': 895, 'specie': 799, 'track': 875, 'across': 23, 'space': 796, 'most': 545, 'diverse': 255, 'animal': 54, 'earth': 265, 'only': 589, 'fraction': 341, 'find': 328, 'formally': 338, 'fact': 320, 'many': 518, 'discover': 248, 'all': 42, 'future': 350, 'unlikely': 896, 'among': 49, 'mean': 525, 'very': 915, 'history': 395, 'role': 734, 'ecosystem': 270, 'instance': 433, 'hoverfly': 401, 'greenland': 372, 'live': 494, 'than': 843, 'mantid': 514, 'brazilian': 113, 'rainforest': 690, 'even': 297, 'within': 949, 'numerous': 578, 'exist': 306, 'own': 604, 'special': 798, 'ecological': 268, 'examine': 301, 'biology': 106, 'catch': 134, 'count': 202, 'lot': 502, 'go': 362, 'without': 950, 'consuming': 193, 'process': 664, 'constrain': 191, 'ability': 13, 'gain': 351, 'insight': 432, 'external': 316, 'factor': 321, 'study': 814, 'publish': 682, 'proceed': 663, 'national': 555, 'academy': 17, 'quickly': 689, 'efficiently': 274, 'forward': 339, 'understand': 890, 'important': 416, 'change': 140, 'response': 724, 'loss': 501, 'habitat': 377, 'climate': 152, 'help': 388, 'collect': 161, 'sit': 775, 'when': 934, 'teach': 834, 'tell': 837, 'apart': 58, 'changer': 141, 'compare': 174, 'binoculars': 102, 'front': 347, 'microscope': 533, 'who': 940, 'senior': 757, 'toke': 866, 'høye': 407, 'bioscience': 107, 'arctic': 62, 'centre': 136, 'aarhus': 12, 'head': 386, 'behind': 93, 'biologist': 105, 'statistician': 807, 'mechanical': 526, 'electrical': 276, 'umbrella': 889, 'term': 839, 'mostly': 546, 'area': 63, 'development': 240, 'driverless': 261, 'car': 128, 'demonstrate': 228, 'alternative': 47, 'laborious': 472, 'observe': 581, 'natural': 556, 'well': 932, 'sort': 794, 'needle': 562, 'hay': 384, 'stack': 805, 'speak': 797, 'specimen': 800, 'rare': 694, 'undescribed': 891, 'widespread': 943, 'trivial': 882, 'demand': 227, 'interpret': 450, 'wealth': 931, 'will': 945, 'indeed': 421, 'ahead': 36, 'invertebrate': 453, 'call': 121, 'entomology': 289, 'thing': 854, 'lack': 473, 'already': 45, 'because': 88, 'proportionally': 676, 'larger': 477, 'share': 764, 'concentrate': 183, 'known': 467, 'like': 489, 'bird': 108, 'mammal': 510, 'expect': 307, 'rapidly': 693, 'knowledge': 466, 'considerably': 189, 'series': 760, 'population': 645, 'observation': 580, 'place': 634, 'over': 603, 'become': 89, 'others': 598, 'mechanism': 527, 'cause': 135, 'critical': 208, 'easy': 267, 'mount': 548, 'location': 497, 'picture': 632, 'local': 495, 'every': 299, 'minute': 538, 'give': 360, 'pile': 633, 'inform': 426, 'respond': 723, 'warmer': 926, 'land': 474, 'management': 511, 'ensure': 287, 'proper': 674, 'balance': 83, 'protection': 678, 'challenge': 139, 'widely': 942, 'available': 79, 'discipline': 247, 'solve': 790, 'here': 389, 'close': 154, 'interdisciplinary': 445, 'collaboration': 159, 'revolutionize': 727, 'roberto': 729, 'morandotti': 543, 'institut': 435, 'de': 221, 'la': 468, 'recherche': 705, 'scientifique': 750, 'inr': 430, 'introduce': 452, 'photonic': 627, 'processor': 666, 'report': 716, 'journal': 460, 'nature': 557, 'layer': 480, 'interconnect': 444, 'neuron': 566, 'great': 369, 'speech': 802, 'recognition': 706, 'medical': 528, 'diagnosis': 242, 'actually': 26, 'electronic': 278, 'limit': 491, 'greater': 370, 'power': 651, 'constantly': 190, 'grow': 374, 'turn': 884, 'themselves': 848, 'electron': 277, 'carry': 132, 'information': 427, 'not': 572, 'much': 550, 'faster': 325, 'basis': 86, 'internet': 449, 'avoid': 80, 'called': 122, 'bottleneck': 110, 'conversion': 196, 'optical': 594, 'signal': 769, 'vice': 916, 'versa': 913, 'propose': 677, 'recognize': 708, 'ultra': 888, 'beyond': 101, 'ten': 838, 'trillion': 881, 'operation': 592, 'expert': 311, 'integrate': 438, 'photonics': 628, 'frequency': 343, 'comb': 167, 'source': 795, 'comprise': 177, 'equally': 291, 'chip': 146, 'efficient': 273, 'device': 241, 'type': 886, 'matrix': 522, 'vector': 910, 'multiplication': 552, 'convolution': 197, 'processing': 665, 'application': 59, 'promise': 673, 'massive': 521, 'face': 319, 'pathology': 612, 'identification': 409, 'clinical': 153, 'scan': 745, 'scalable': 743, 'trainable': 878, 'complex': 176, 'unman': 897, 'far': 324, 'integration': 439, 'coming': 170, 'display': 251, 'glimmer': 361, 'empathy': 280, 'partner': 609, 'longtime': 499, 'couple': 204, 'predict': 654, 'columbia': 166, 'action': 24, 'base': 84, 'few': 326, 'frame': 342, 'primate': 658, 'cooped': 198, 'together': 865, 'roommate': 737, 'co': 156, 'worker': 953, 'family': 323, 'member': 530, 'anticipate': 56, 'easier': 266, 'successfully': 819, 'intelligent': 441, 'remain': 712, 'notoriously': 574, 'inept': 423, 'social': 785, 'communication': 172, 'may': 524, 'conduct': 185, 'creative': 207, 'lead': 481, 'hod': 396, 'lipson': 493, 'broader': 115, 'endow': 282, 'purely': 683, 'visual': 921, 'playpen': 638, 'roughly': 738, '3x2': 9, 'foot': 334, 'size': 778, 'seek': 755, 'green': 371, 'circle': 148, 'sometimes': 792, 'directly': 246, 'occlude': 583, 'tall': 832, 'red': 709, 'carboard': 129, 'box': 111, 'case': 133, 'putter': 685, 'path': 611, 'eventually': 298, '98': 11, '100': 1, 'vary': 909, 'situation': 776, 'explicitly': 313, 'visibility': 919, 'handicap': 379, 'excite': 303, 'boyuan': 112, 'chen': 144, 'author': 74, 'carl': 131, 'vondrick': 924, 'today': 864, 'scientific': 749, 'observer': 582, 'itself': 458, 'shoe': 765, 'guide': 376, 'whether': 936, 'perhaps': 618, 'primitive': 659, 'prediction': 655, 'subject': 815, 'what': 933, 'however': 403, 'accurately': 20, 'foresee': 336, 'colleague': 160, 'cue': 209, 'acknowledge': 21, 'behavior': 92, 'exhibit': 305, 'simpler': 773, 'cognitive': 158, 'theory': 850, 'mind': 537, 'tom': 867, 'age': 34, 'three': 860, 'child': 145, 'playful': 637, 'activity': 25, 'hide': 390, 'sophisticate': 793, 'manipulation': 513, 'lie': 486, 'broadly': 116, 'key': 463, 'distinguish': 253, 'hallmark': 378, 'cognition': 157, 'adaptive': 27, 'cooperation': 199, 'competition': 175, 'deception': 222, 'better': 99, 'verbal': 912, 'language': 475, 'rather': 695, 'word': 951, 'entangle': 288, 'thorny': 857, 'speculate': 801, 'visually': 922, 'unique': 893, 'think': 855, 'frequently': 344, 'imagine': 413, 'eye': 318, 'ethical': 294, 'question': 688, 'resilient': 720, 'manipulate': 512, 'thought': 859, 'passive': 610, 'instruction': 437, 'following': 332, 'hope': 398, 'policymakers': 643, 'keep': 462, 'check': 143, 'revolution': 726, 'urban': 901, 'drone': 263, 'transform': 879, 'city': 150, 'people': 614, 'wildlife': 944, '170': 3, 'leeds': 483, 'ass': 70, 'opportunity': 593, 'cutting': 212, 'edge': 271, 'highlight': 393, 'improve': 417, 'monitor': 542, 'emerge': 279, 'pest': 623, 'plant': 636, 'engage': 283, 'appreciate': 60, 'pollution': 644, 'traffic': 876, 'congestion': 187, 'reduce': 710, 'town': 873, 'pleasant': 639, 'spend': 804, 'outside': 602, 'warn': 927, 'automation': 76, 'damage': 216, 'might': 534, 'waste': 928, 'substantial': 816, 'negative': 563, 'implication': 415, 'planned': 635, 'enough': 286, 'operate': 591, 'inequality': 424, 'unequal': 892, 'dr': 259, 'martin': 520, 'dallimer': 215, 'school': 747, 'potential': 649, 'almost': 44, 'aspect': 69, 'society': 786, 'vital': 923, 'proactively': 661, 'try': 883, 'side': 768, 'effect': 272, 'risk': 728, 'automate': 75, 'although': 48, 'impact': 414, 'hard': 381, 'sure': 824, 'public': 680, 'policy': 642, 'maker': 509, 'developer': 239, 'aware': 81, 'pro': 660, 'con': 182, 'detrimental': 237, 'consequence': 188, 'fully': 349, 'realise': 700, 'ecology': 269, 'evolution': 300, '77': 10, 'academic': 16, 'practitioner': 652, 'online': 588, 'survey': 825, '35': 5, 'country': 203, 'best': 98, 'guess': 375, 'hold': 397, 'participant': 607, 'view': 918, 'biodiversity': 103, 'define': 225, 'analyse': 52, 'aerial': 31, 'self': 756, 'driving': 262, 'repair': 715, 'infrastructure': 428, 'wireless': 947, 'sensor': 759, 'range': 692, 'transport': 880, 'collection': 162, 'maintenance': 507, 'police': 641, 'precision': 653, 'project': 672, 'aim': 38, 'maintain': 506, 'disruption': 252, 'citizen': 149, 'mark': 519, 'goddard': 364, 'whilst': 939, 'northumbria': 571, 'bring': 114, 'being': 94, 'likely': 490, 'experience': 309, 'affect': 32, 'support': 823, 'accessible': 19}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PcAFlxNJ6eK1"},"source":["5.) Sort dictionary and create first \"wf\" dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-FIFlJr6wA_","executionInfo":{"status":"ok","timestamp":1622564034200,"user_tz":-120,"elapsed":345,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}},"outputId":"b1376aa5-6989-4ea9-9a85-b00f0229352c"},"source":["# sort the values\n","sorted_values = sorted(dic.values()) \n","\n","# empty dictionary\n","sorted_dict = {}\n","\n","# sort dictionary\n","for i in sorted_values:\n","    for k in dic.keys():\n","        if dic[k] == i:\n","            sorted_dict[k] = dic[k]\n","            break\n","\n","# convert to pandas dataframe with custom index and column names\n","df1 = pd.DataFrame(arr, columns=sorted_dict.keys(), index=['text1', 'text2', 'text3', 'text4', 'text5'])\n","print(\"wf: \")\n","print(df1)\n","\n","# shape of matrix\n","rows = arr.shape[0]\n","cols = arr.shape[1]"],"execution_count":6,"outputs":[{"output_type":"stream","text":["wf: \n","       000  100  14  170  2020  35  ...  worker  world  would  year  yet  you\n","text1    1    0   1    0     1   0  ...       0      2      6     1    1    4\n","text2    0    0   0    0     0   0  ...       0      0      0     3    0    0\n","text3    0    0   0    0     0   0  ...       0      0      0     0    1    0\n","text4    0    1   0    0     0   0  ...       1      1      3     0    1    0\n","text5    0    0   0    2     0   1  ...       0      2      0     0    0    0\n","\n","[5 rows x 959 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oBwipFmq6_4Y"},"source":["6.) Create binary function and transform it to dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUQsWpSj7lUr","executionInfo":{"status":"ok","timestamp":1622564034201,"user_tz":-120,"elapsed":11,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}},"outputId":"c069682a-839d-4450-ca74-88a9a5a56a6b"},"source":["# binary function\n","arr1 = arr.copy()\n","\n","for x in range(0, rows):\n","    for y in range(0, cols):\n","        if arr[x,y] > 0:\n","          arr1[x,y] = 1\n","        else:\n","          arr1[x,y] = 0 \n","\n","# binary sum of words in documents\n","binary_arr1 = arr1.sum(axis=0)\n","\n","# create dataframe for binary function\n","df2 = pd.DataFrame(arr1, columns=sorted_dict.keys(), index=['text1', 'text2', 'text3', 'text4', 'text5'])\n","print(\"binary: \")\n","print(df2)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["binary: \n","       000  100  14  170  2020  35  ...  worker  world  would  year  yet  you\n","text1    1    0   1    0     1   0  ...       0      1      1     1    1    1\n","text2    0    0   0    0     0   0  ...       0      0      0     1    0    0\n","text3    0    0   0    0     0   0  ...       0      0      0     0    1    0\n","text4    0    1   0    0     0   0  ...       1      1      1     0    1    0\n","text5    0    0   0    1     0   1  ...       0      1      0     0    0    0\n","\n","[5 rows x 959 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ugx68HkX70Q1"},"source":["7.) Create logarithmic function and transform it to dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqRNJx3d8Tlh","executionInfo":{"status":"ok","timestamp":1622564034202,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}},"outputId":"4dac72f2-ad24-47df-c739-c19f38b6b954"},"source":["# logarithmic function\n","arr2 = arr.copy().astype(np.float)\n","for x in range(0, rows):\n","    for y in range(0, cols):\n","        if arr[x,y] > 0:\n","          arr2[x,y] = 1 + math.log(arr[x,y],10)\n","        else:\n","          arr2[x,y] = 0\n","\n","# create dataframe for logarithmic function\n","df3 = pd.DataFrame(arr2, columns=sorted_dict.keys(), index=['text1', 'text2', 'text3', 'text4', 'text5'])\n","print(\"logarithmic: \")\n","print(df3)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["logarithmic: \n","       000  100   14      170  2020  ...    world     would      year  yet      you\n","text1  1.0  0.0  1.0  0.00000   1.0  ...  1.30103  1.778151  1.000000  1.0  1.60206\n","text2  0.0  0.0  0.0  0.00000   0.0  ...  0.00000  0.000000  1.477121  0.0  0.00000\n","text3  0.0  0.0  0.0  0.00000   0.0  ...  0.00000  0.000000  0.000000  1.0  0.00000\n","text4  0.0  1.0  0.0  0.00000   0.0  ...  1.00000  1.477121  0.000000  1.0  0.00000\n","text5  0.0  0.0  0.0  1.30103   0.0  ...  1.30103  0.000000  0.000000  0.0  0.00000\n","\n","[5 rows x 959 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P9Qgcf2D8d0a"},"source":["8.) Create inverse function and transform it to dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"svLiSz2-8lAz","executionInfo":{"status":"ok","timestamp":1622564034399,"user_tz":-120,"elapsed":201,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}},"outputId":"3dd63e0d-46d4-4679-d824-08d9d2ebee7b"},"source":["# inverse function\n","arr3 = arr.copy().astype(np.float)\n","for x in range(0, rows):\n","    for y in range(0, cols):\n","        if arr[x,y] > 0:\n","          arr3[x,y] = arr2[x,y] * math.log(5/binary_arr1[y],10)\n","        else:\n","          0\n","\n","# create dataframe for inverse function\n","df4 = pd.DataFrame(arr3, columns=sorted_dict.keys(), index=['text1', 'text2', 'text3', 'text4', 'text5'])\n","print(\"inverse: \")\n","print(df4)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["inverse: \n","           000      100       14  ...      year       yet       you\n","text1  0.69897  0.00000  0.69897  ...  0.397940  0.221849  1.119792\n","text2  0.00000  0.00000  0.00000  ...  0.587806  0.000000  0.000000\n","text3  0.00000  0.00000  0.00000  ...  0.000000  0.221849  0.000000\n","text4  0.00000  0.69897  0.00000  ...  0.000000  0.221849  0.000000\n","text5  0.00000  0.00000  0.00000  ...  0.000000  0.000000  0.000000\n","\n","[5 rows x 959 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XsKyHLNO8wn1"},"source":["9.) Export to excel"]},{"cell_type":"code","metadata":{"id":"CgA7BnO5rIwj","executionInfo":{"status":"ok","timestamp":1622564035962,"user_tz":-120,"elapsed":1566,"user":{"displayName":"Ľudovít Laca","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_8RtneW7PgTTuiCnx0VUNQNyApN5rCT7UJZW89w=s64","userId":"17075019361640864910"}}},"source":["# export to excel\n","with pd.ExcelWriter('reprezentacia_textu_2.xlsx') as writer:  \n","    df1.to_excel(writer, sheet_name='wf')\n","    df2.to_excel(writer, sheet_name='binarna')\n","    df3.to_excel(writer, sheet_name='logaritmicka')\n","    df4.to_excel(writer, sheet_name='inverzna')"],"execution_count":10,"outputs":[]}]}